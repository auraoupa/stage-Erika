{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/bokeh/core.py:74: UserWarning: \n",
      "Failed to start diagnostics server on port 8787. [Errno 13] Permission denied\n",
      "  warnings.warn(\"\\n\" + msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://172.30.100.4:46387\n",
       "  <li><b>Dashboard: </b><a href='http://172.30.100.4:45139/status' target='_blank'>http://172.30.100.4:45139/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>0</li>\n",
       "  <li><b>Cores: </b>0</li>\n",
       "  <li><b>Memory: </b>0 B</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://172.30.100.4:46387' processes=0 cores=0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask_jobqueue import SLURMCluster \n",
    "from dask.distributed import Client \n",
    "  \n",
    "cluster = SLURMCluster(cores=28,name='make_profiles',walltime='00:30:00',job_extra=['--constraint=HSW24','--exclusive','--nodes=1'],memory='120GB',interface='ib0') \n",
    "cluster.scale(196)\n",
    "cluster\n",
    "\n",
    "from dask.distributed import Client\n",
    "client = Client(cluster)\n",
    "client\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "           9955291     hsw24 make_pro albert7a PD       0:00      1 (Priority)\n",
      "           9955292     hsw24 make_pro albert7a PD       0:00      1 (Priority)\n",
      "           9955293     hsw24 make_pro albert7a PD       0:00      1 (Priority)\n",
      "           9955294     hsw24 make_pro albert7a PD       0:00      1 (Priority)\n",
      "           9955295     hsw24 make_pro albert7a PD       0:00      1 (Priority)\n",
      "           9955296     hsw24 make_pro albert7a PD       0:00      1 (Priority)\n",
      "           9955297     hsw24 make_pro albert7a PD       0:00      1 (Priority)\n",
      "132\n"
     ]
    }
   ],
   "source": [
    "!squeue -u albert7a\n",
    "\n",
    "import time\n",
    "nb_workers = 0\n",
    "while True:\n",
    "    nb_workers = len(client.scheduler_info()[\"workers\"])\n",
    "    if nb_workers >= 2:\n",
    "        break\n",
    "    time.sleep(1)\n",
    "print(nb_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Path for modules\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "sys.path.insert(0,\"/scratch/cnt0024/hmg2840/albert7a/DEV/git/xscale\")\n",
    "import xscale\n",
    "import xscale.spectral.fft as xfft\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "\n",
    "import numpy.ma as ma\n",
    "\n",
    "import matplotlib.cm as mplcm\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib import gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from datetime import date, datetime\n",
    "#from xhistogram.xarray import histogram\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def curl(u,v,e1v,e2u,ff):\n",
    "    '''\n",
    "    This routine computes the relative vorticity from 2D fields of horizontal velocities and the spatial Coriolis parameter.\n",
    "    '''\n",
    "    #Computation of dy(u)\n",
    "    fe2u=1/e2u\n",
    "    fse2u=fe2u.squeeze()\n",
    "    dyu=(u.shift(y=-1) - u)*fse2u\n",
    "    #Computation of dx(v)\n",
    "    fe1v=1/e1v\n",
    "    fse1v=fe1v.squeeze()\n",
    "    dxv=(v.shift(x=-1) - v)*fse1v\n",
    "    #Projection on the grid T\n",
    "    dxvt=0.5*(dxv.shift(y=-1)+dxv)\n",
    "    dyut=0.5*(dyu.shift(x=-1)+dyu)\n",
    "    #Computation of the vorticity divided by f\n",
    "    fff=1/ff\n",
    "    curl=(dxvt-dyut)*fff\n",
    "    return curl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strain(u,v,e1u,e1v,e2u,e2v,ff):\n",
    "    '''\n",
    "    This routine computes the relative vorticity from 2D fields of horizontal velocities and the spatial Coriolis parameter.\n",
    "    '''\n",
    "    #Computation of dy(u)\n",
    "    fe2u=1/e2u\n",
    "    fse2u=fe2u.squeeze()\n",
    "    dyu=(u.shift(y=-1) - u)*fse2u\n",
    "    #Computation of dx(v)\n",
    "    fe1v=1/e1v\n",
    "    fse1v=fe1v.squeeze()\n",
    "    dxv=(v.shift(x=-1) - v)*fse1v\n",
    "    #Computation of dy(v)\n",
    "    fe2v=1/e2v\n",
    "    fse2v=fe2v.squeeze()\n",
    "    dyv=(v.shift(y=-1) - v)*fse2v\n",
    "    #Computation of dx(u)\n",
    "    fe1u=1/e1u\n",
    "    fse1u=fe1u.squeeze()\n",
    "    dxu=(u.shift(x=-1) - u)*fse1u\n",
    "    #Projection on the grid T\n",
    "    dxvt=0.5*(dxv.shift(y=-1)+dxv)\n",
    "    dyut=0.5*(dyu.shift(x=-1)+dyu)\n",
    "    dxut=0.5*(dxu.shift(x=-1)+dxu)\n",
    "    dyvt=0.5*(dyv.shift(y=-1)+dyv)\n",
    "    #Computation of the strain divided by f\n",
    "    fff=1/ff\n",
    "    strain=np.sqrt( (dyut+dxvt)*(dyut+dxvt) + (dxut-dyvt)*(dxut-dyvt) ) *fff\n",
    "    return strain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset : grid files and one example of U and V for test\n",
    "\n",
    "\n",
    "# Opening grid files\n",
    "\n",
    "dirgrid='/scratch/cnt0024/hmg2840/albert7a/eNATL60/eNATL60-I/'\n",
    "gridfile=dirgrid+'mesh_hgr_eNATL60ACO_3.6.nc'\n",
    "dsgrid=xr.open_dataset(gridfile,chunks={'x':200,'y':200})\n",
    "\n",
    "e1u=dsgrid.e1u\n",
    "e1v=dsgrid.e1v\n",
    "e2u=dsgrid.e2u\n",
    "e2v=dsgrid.e2v\n",
    "ff=dsgrid.ff\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Opening u & v grid files\n",
    "    # With tide\n",
    "\n",
    "    dirvarT0='/scratch/cnt0024/hmg2840/albert7a/eNATL60/eNATL60-BLBT02-S/1h/ACO/'\n",
    "    ufileT0=dirvarT0+'eNATL60ACO-BLBT02_y2009m*.1h_vozocrtx10m.nc' # JAS\n",
    "    vfileT0=dirvarT0+'eNATL60ACO-BLBT02_y2009m*.1h_vomecrty10m.nc' # JAS\n",
    "    dsuT0=xr.open_mfdataset(ufileT0,combine='by_coords',parallel=True,chunks={'time_counter':1008,'x':100,'y':1000})\n",
    "    dsvT0=xr.open_mfdataset(vfileT0,combine='by_coords',parallel=True,chunks={'time_counter':1008,'x':100,'y':1000})\n",
    "    uT0=dsuT0.vozocrtx\n",
    "    vT0=dsvT0.vomecrty \n",
    "    lon=dsuT0.nav_lon\n",
    "    lat=dsuT0.nav_lat\n",
    "\n",
    "    # Without tide\n",
    "\n",
    "    dirvar00='/scratch/cnt0024/hmg2840/albert7a/eNATL60/eNATL60-BLB002-S/1h/ACO/'\n",
    "    ufile00=dirvar00+'eNATL60ACO-BLB002_y2009m*.1h_vozocrtx10m.nc' # JAS\n",
    "    vfile00=dirvar00+'eNATL60ACO-BLB002_y2009m*.1h_vomecrty10m.nc' # JAS\n",
    "    dsu00=xr.open_mfdataset(ufile00,combine='by_coords',parallel=True,chunks={'time_counter':1008,'x':100,'y':1000})\n",
    "    dsv00=xr.open_mfdataset(vfile00,combine='by_coords',parallel=True,chunks={'time_counter':1008,'x':100,'y':1000})\n",
    "    u00=dsu00.vozocrtx\n",
    "    v00=dsv00.vomecrty# Filtering of u & v\n",
    "\n",
    "    T=2*np.pi/(1E-4) # Coriolis period\n",
    "\n",
    "    wuT0 = uT0.window\n",
    "    wuT0.set(n=48,dim='time_counter', cutoff=2*T)\n",
    "    uT0_filt = wuT0.convolve()\n",
    "\n",
    "    wu00 = u00.window\n",
    "    wu00.set(n=48,dim='time_counter', cutoff=2*T)\n",
    "    u00_filt = wu00.convolve()\n",
    "\n",
    "    wvT0 = vT0.window\n",
    "    wvT0.set(n=48,dim='time_counter', cutoff=2*T)\n",
    "    vT0_filt = wvT0.convolve()\n",
    "\n",
    "    wv00 = v00.window\n",
    "    wv00.set(n=48,dim='time_counter', cutoff=2*T)\n",
    "    v00_filt = wv00.convolve()\n",
    "    ### Compute curl and strain with python\n",
    "\n",
    "    curlT0_filt   = curl(uT0_filt,vT0_filt,e1v,e2u,ff)\n",
    "    curl00_filt   = curl(u00_filt,v00_filt,e1v,e2u,ff)\n",
    "    strainT0_filt = strain(uT0_filt,vT0_filt,e1u,e1v,e2u,e2v,ff)\n",
    "    strain00_filt = strain(u00_filt,v00_filt,e1u,e1v,e2u,e2v,ff)\n",
    "\n",
    "#    curlT0_filt_da=xr.DataArray(curlT0_filt.squeeze(),dims=['time_counter','y','x'],name=\"Curl_Tide_Filt\",coords=['lon','lat'])\n",
    "#    curlT0_filt_da.attrs['Name']='eNATL60ACO-BLBT02_y2009m07-09_socurloverf10m_filt2T.nc'\n",
    "#    curlT0_filt_da.to_dataset().to_netcdf(path='/scratch/cnt0024/hmg2840/albert7a/eNATL60/eNATL60-BLBT02-S/1h/ACO/eNATL60ACO-BLBT02_y2009m07-09_socurloverf10m_filt2T.nc',mode='w',engine='scipy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "coords is not dict-like, but it has 2 items, which does not match the 3 dimensions of the data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/dataarray.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, coords, dims, name, attrs, encoding, indexes, fastpath)\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_data_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_compatible_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m             \u001b[0mcoords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_infer_coords_and_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m             \u001b[0mvariable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/dataarray.py\u001b[0m in \u001b[0;36m_infer_coords_and_dims\u001b[0;34m(shape, coords, dims)\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;34m\"coords is not dict-like, but it has %s items, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;34m\"which does not match the %s dimensions of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0;34m\"data\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         )\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: coords is not dict-like, but it has 2 items, which does not match the 3 dimensions of the data"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "curl00_filt_da=xr.DataArray(curl00_filt.squeeze(),dims=['time_counter','y','x'],name=\"Curl_noTide_Filt\",coords=['lon','lat'])\n",
    "Jupyter Notebook\n",
    "2020-04-02-AA-write-curl-strain-filt-ACO-all-files-on-occigen (auto-sauvegardé) Current Kernel Logo \n",
    "\n",
    "Python 3\n",
    "\n",
    "    Fichier\n",
    "    Édition\n",
    "    Affichage\n",
    "    Insérer\n",
    "    Cellule\n",
    "    Noyau\n",
    "    Widgets\n",
    "    Aide\n",
    "\n",
    "from dask_jobqueue import SLURMCluster \n",
    "\n",
    "from dask.distributed import Client \n",
    "\n",
    "  \n",
    "\n",
    "cluster = SLURMCluster(cores=28,name='make_profiles',walltime='00:30:00',job_extra=['--constraint=HSW24','--exclusive','--nodes=1'],memory='120GB',interface='ib0') \n",
    "\n",
    "cluster.scale(196)\n",
    "\n",
    "cluster\n",
    "\n",
    "​\n",
    "\n",
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(cluster)\n",
    "\n",
    "client\n",
    "\n",
    "​\n",
    "\n",
    "​\n",
    "\n",
    "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
    "  data = yaml.load(f.read()) or {}\n",
    "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/bokeh/core.py:74: UserWarning: \n",
    "Failed to start diagnostics server on port 8787. [Errno 13] Permission denied\n",
    "  warnings.warn(\"\\n\" + msg)\n",
    "\n",
    "Client\n",
    "\n",
    "    Scheduler: tcp://172.30.100.4:46387\n",
    "    Dashboard: http://172.30.100.4:45139/status \n",
    "\n",
    "\t\n",
    "Cluster\n",
    "\n",
    "    Workers: 0\n",
    "    Cores: 0\n",
    "    Memory: 0 B\n",
    "\n",
    "!squeue -u albert7a\n",
    "\n",
    "​\n",
    "\n",
    "import time\n",
    "\n",
    "nb_workers = 0\n",
    "\n",
    "while True:\n",
    "\n",
    "    nb_workers = len(client.scheduler_info()[\"workers\"])\n",
    "\n",
    "    if nb_workers >= 2:\n",
    "\n",
    "        break\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "print(nb_workers)\n",
    "\n",
    "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
    "           9955291     hsw24 make_pro albert7a PD       0:00      1 (Priority)\n",
    "           9955292     hsw24 make_pro albert7a PD       0:00      1 (Priority)\n",
    "           9955293     hsw24 make_pro albert7a PD       0:00      1 (Priority)\n",
    "           9955294     hsw24 make_pro albert7a PD       0:00      1 (Priority)\n",
    "           9955295     hsw24 make_pro albert7a PD       0:00      1 (Priority)\n",
    "           9955296     hsw24 make_pro albert7a PD       0:00      1 (Priority)\n",
    "           9955297     hsw24 make_pro albert7a PD       0:00      1 (Priority)\n",
    "132\n",
    "\n",
    "## Path for modules\n",
    "\n",
    "​\n",
    "\n",
    "import sys\n",
    "\n",
    "​\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "​\n",
    "\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "​\n",
    "\n",
    "sys.path.insert(0,\"/scratch/cnt0024/hmg2840/albert7a/DEV/git/xscale\")\n",
    "\n",
    "import xscale\n",
    "\n",
    "import xscale.spectral.fft as xfft\n",
    "\n",
    "​\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "\n",
    "​\n",
    "\n",
    "import numpy.ma as ma\n",
    "\n",
    "​\n",
    "\n",
    "import matplotlib.cm as mplcm\n",
    "\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "from matplotlib import gridspec\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "​\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "from datetime import date, datetime\n",
    "\n",
    "#from xhistogram.xarray import histogram\n",
    "\n",
    "​\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "​\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "​\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def curl(u,v,e1v,e2u,ff):\n",
    "\n",
    "    '''\n",
    "\n",
    "    This routine computes the relative vorticity from 2D fields of horizontal velocities and the spatial Coriolis parameter.\n",
    "\n",
    "    '''\n",
    "\n",
    "    #Computation of dy(u)\n",
    "\n",
    "    fe2u=1/e2u\n",
    "\n",
    "    fse2u=fe2u.squeeze()\n",
    "\n",
    "    dyu=(u.shift(y=-1) - u)*fse2u\n",
    "\n",
    "    #Computation of dx(v)\n",
    "\n",
    "    fe1v=1/e1v\n",
    "\n",
    "    fse1v=fe1v.squeeze()\n",
    "\n",
    "    dxv=(v.shift(x=-1) - v)*fse1v\n",
    "\n",
    "    #Projection on the grid T\n",
    "\n",
    "    dxvt=0.5*(dxv.shift(y=-1)+dxv)\n",
    "\n",
    "    dyut=0.5*(dyu.shift(x=-1)+dyu)\n",
    "\n",
    "    #Computation of the vorticity divided by f\n",
    "\n",
    "    fff=1/ff\n",
    "\n",
    "    curl=(dxvt-dyut)*fff\n",
    "\n",
    "    return curl\n",
    "\n",
    "def strain(u,v,e1u,e1v,e2u,e2v,ff):\n",
    "\n",
    "    '''\n",
    "\n",
    "    This routine computes the relative vorticity from 2D fields of horizontal velocities and the spatial Coriolis parameter.\n",
    "\n",
    "    '''\n",
    "\n",
    "    #Computation of dy(u)\n",
    "\n",
    "    fe2u=1/e2u\n",
    "\n",
    "    fse2u=fe2u.squeeze()\n",
    "\n",
    "    dyu=(u.shift(y=-1) - u)*fse2u\n",
    "\n",
    "    #Computation of dx(v)\n",
    "\n",
    "    fe1v=1/e1v\n",
    "\n",
    "    fse1v=fe1v.squeeze()\n",
    "\n",
    "    dxv=(v.shift(x=-1) - v)*fse1v\n",
    "\n",
    "    #Computation of dy(v)\n",
    "\n",
    "    fe2v=1/e2v\n",
    "\n",
    "    fse2v=fe2v.squeeze()\n",
    "\n",
    "    dyv=(v.shift(y=-1) - v)*fse2v\n",
    "\n",
    "    #Computation of dx(u)\n",
    "\n",
    "    fe1u=1/e1u\n",
    "\n",
    "    fse1u=fe1u.squeeze()\n",
    "\n",
    "    dxu=(u.shift(x=-1) - u)*fse1u\n",
    "\n",
    "    #Projection on the grid T\n",
    "\n",
    "    dxvt=0.5*(dxv.shift(y=-1)+dxv)\n",
    "\n",
    "    dyut=0.5*(dyu.shift(x=-1)+dyu)\n",
    "\n",
    "    dxut=0.5*(dxu.shift(x=-1)+dxu)\n",
    "\n",
    "    dyvt=0.5*(dyv.shift(y=-1)+dyv)\n",
    "\n",
    "    #Computation of the strain divided by f\n",
    "\n",
    "    fff=1/ff\n",
    "\n",
    "    strain=np.sqrt( (dyut+dxvt)*(dyut+dxvt) + (dxut-dyvt)*(dxut-dyvt) ) *fff\n",
    "\n",
    "    return strain\n",
    "\n",
    "## Dataset : grid files and one example of U and V for test\n",
    "\n",
    "​\n",
    "\n",
    "​\n",
    "\n",
    "# Opening grid files\n",
    "\n",
    "​\n",
    "\n",
    "dirgrid='/scratch/cnt0024/hmg2840/albert7a/eNATL60/eNATL60-I/'\n",
    "\n",
    "gridfile=dirgrid+'mesh_hgr_eNATL60ACO_3.6.nc'\n",
    "\n",
    "dsgrid=xr.open_dataset(gridfile,chunks={'x':200,'y':200})\n",
    "\n",
    "​\n",
    "\n",
    "e1u=dsgrid.e1u\n",
    "\n",
    "e1v=dsgrid.e1v\n",
    "\n",
    "e2u=dsgrid.e2u\n",
    "\n",
    "e2v=dsgrid.e2v\n",
    "\n",
    "ff=dsgrid.ff\n",
    "\n",
    "​\n",
    "\n",
    "​\n",
    "\n",
    "​\n",
    "\n",
    "​\n",
    "\n",
    "    # Opening u & v grid files\n",
    "\n",
    "    # With tide\n",
    "\n",
    "​\n",
    "\n",
    "    dirvarT0='/scratch/cnt0024/hmg2840/albert7a/eNATL60/eNATL60-BLBT02-S/1h/ACO/'\n",
    "\n",
    "    ufileT0=dirvarT0+'eNATL60ACO-BLBT02_y2009m*.1h_vozocrtx10m.nc' # JAS\n",
    "\n",
    "    vfileT0=dirvarT0+'eNATL60ACO-BLBT02_y2009m*.1h_vomecrty10m.nc' # JAS\n",
    "\n",
    "    dsuT0=xr.open_mfdataset(ufileT0,combine='by_coords',parallel=True,chunks={'time_counter':1008,'x':100,'y':1000})\n",
    "\n",
    "    dsvT0=xr.open_mfdataset(vfileT0,combine='by_coords',parallel=True,chunks={'time_counter':1008,'x':100,'y':1000})\n",
    "\n",
    "    uT0=dsuT0.vozocrtx\n",
    "\n",
    "    vT0=dsvT0.vomecrty \n",
    "\n",
    "    lon=dsuT0.nav_lon\n",
    "\n",
    "    lat=dsuT0.nav_lat\n",
    "\n",
    "​\n",
    "\n",
    "    # Without tide\n",
    "\n",
    "​\n",
    "\n",
    "    dirvar00='/scratch/cnt0024/hmg2840/albert7a/eNATL60/eNATL60-BLB002-S/1h/ACO/'\n",
    "\n",
    "    ufile00=dirvar00+'eNATL60ACO-BLB002_y2009m*.1h_vozocrtx10m.nc' # JAS\n",
    "\n",
    "    vfile00=dirvar00+'eNATL60ACO-BLB002_y2009m*.1h_vomecrty10m.nc' # JAS\n",
    "\n",
    "    dsu00=xr.open_mfdataset(ufile00,combine='by_coords',parallel=True,chunks={'time_counter':1008,'x':100,'y':1000})\n",
    "\n",
    "    dsv00=xr.open_mfdataset(vfile00,combine='by_coords',parallel=True,chunks={'time_counter':1008,'x':100,'y':1000})\n",
    "\n",
    "    u00=dsu00.vozocrtx\n",
    "\n",
    "    v00=dsv00.vomecrty# Filtering of u & v\n",
    "\n",
    "​\n",
    "\n",
    "    T=2*np.pi/(1E-4) # Coriolis period\n",
    "\n",
    "​\n",
    "\n",
    "    wuT0 = uT0.window\n",
    "\n",
    "    wuT0.set(n=48,dim='time_counter', cutoff=2*T)\n",
    "\n",
    "    uT0_filt = wuT0.convolve()\n",
    "\n",
    "​\n",
    "\n",
    "    wu00 = u00.window\n",
    "\n",
    "    wu00.set(n=48,dim='time_counter', cutoff=2*T)\n",
    "\n",
    "    u00_filt = wu00.convolve()\n",
    "\n",
    "​\n",
    "\n",
    "    wvT0 = vT0.window\n",
    "\n",
    "    wvT0.set(n=48,dim='time_counter', cutoff=2*T)\n",
    "\n",
    "    vT0_filt = wvT0.convolve()\n",
    "\n",
    "​\n",
    "\n",
    "    wv00 = v00.window\n",
    "\n",
    "    wv00.set(n=48,dim='time_counter', cutoff=2*T)\n",
    "\n",
    "    v00_filt = wv00.convolve()\n",
    "\n",
    "    ### Compute curl and strain with python\n",
    "\n",
    "​\n",
    "\n",
    "    curlT0_filt   = curl(uT0_filt,vT0_filt,e1v,e2u,ff)\n",
    "\n",
    "    curl00_filt   = curl(u00_filt,v00_filt,e1v,e2u,ff)\n",
    "\n",
    "    strainT0_filt = strain(uT0_filt,vT0_filt,e1u,e1v,e2u,e2v,ff)\n",
    "\n",
    "    strain00_filt = strain(u00_filt,v00_filt,e1u,e1v,e2u,e2v,ff)\n",
    "\n",
    "​\n",
    "\n",
    "#    curlT0_filt_da=xr.DataArray(curlT0_filt.squeeze(),dims=['time_counter','y','x'],name=\"Curl_Tide_Filt\",coords=['lon','lat'])\n",
    "\n",
    "#    curlT0_filt_da.attrs['Name']='eNATL60ACO-BLBT02_y2009m07-09_socurloverf10m_filt2T.nc'\n",
    "\n",
    "#    curlT0_filt_da.to_dataset().to_netcdf(path='/scratch/cnt0024/hmg2840/albert7a/eNATL60/eNATL60-BLBT02-S/1h/ACO/eNATL60ACO-BLBT02_y2009m07-09_socurloverf10m_filt2T.nc',mode='w',engine='scipy')\n",
    "\n",
    "​\n",
    "\n",
    "​\n",
    "\n",
    "\n",
    "curl00_filt_da.attrs['Name']='eNATL60ACO-BLB002_y2009m07-09_socurloverf10m_filt2T.nc'\n",
    "curl00_filt_da.to_dataset().to_netcdf(path='/scratch/cnt0024/hmg2840/albert7a/eNATL60/eNATL60-BLB002-S/1h/ACO/eNATL60ACO-BLB002_y2009m07-09_socurloverf10m_filt2T.nc',mode='w',engine='scipy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "strainT0_filt_da=xr.DataArray(strainT0_filt.squeeze(),dims=['time_counter','y','x'],name=\"strain_Tide_Filt\",coords=['lon','lat'])\n",
    "strainT0_filt_da.attrs['Name']='eNATL60ACO-BLBT02_y2009m07-09_sostrainoverf10m_filt2T.nc'\n",
    "strainT0_filt_da.to_dataset().to_netcdf(path='/scratch/cnt0024/hmg2840/albert7a/eNATL60/eNATL60-BLBT02-S/1h/ACO/eNATL60ACO-BLBT02_y2009m07-09_sostrainoverf10m_filt2T.nc',mode='w',engine='scipy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "strain00_filt_da=xr.DataArray(strain00_filt.squeeze(),dims=['time_counter','y','x'],name=\"strain_noTide_Filt\",coords=['lon','lat'])\n",
    "strain00_filt_da.attrs['Name']='eNATL60ACO-BLB002_y2009m07-09_sostrainoverf10m_filt2T.nc'\n",
    "strain00_filt_da.to_dataset().to_netcdf(path='/scratch/cnt0024/hmg2840/albert7a/eNATL60/eNATL60-BLB002-S/1h/ACO/eNATL60ACO-BLB002_y2009m07-09_sostrainoverf10m_filt2T.nc',mode='w',engine='scipy')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
