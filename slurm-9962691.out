/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.149:39438'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.149:43812'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.149:33123'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.149:45605'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.149:39584'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.149:34730'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.149:42594'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.149:40650'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.149:35524'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.149:42932'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.149:33486'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.149:35819'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.149:42850'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.149:40790'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.149:45937'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.149:42336'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.149:46307'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.149:38043'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.149:32881'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.149:45783'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.149:33665'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.149:40730'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.149:41178'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.149:34853'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.149:34282'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.149:33124'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.149:36102'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.149:44106'
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-toq6mwx_', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-_6rhyy7a', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-k1crvk45', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-85efj1c0', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-2l6pygng', purging
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.149:33285
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.149:44780
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.149:42207
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.149:36650
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.149:41747
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.149:38348
distributed.worker - INFO -          Listening to:   tcp://172.30.6.149:33285
distributed.worker - INFO -          Listening to:   tcp://172.30.6.149:44780
distributed.worker - INFO -          Listening to:   tcp://172.30.6.149:42207
distributed.worker - INFO -          Listening to:   tcp://172.30.6.149:36650
distributed.worker - INFO -          Listening to:   tcp://172.30.6.149:41747
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.149:45718
distributed.worker - INFO -          Listening to:   tcp://172.30.6.149:38348
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.149:35850
distributed.worker - INFO -              nanny at:         172.30.6.149:38043
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.149:46683
distributed.worker - INFO -              nanny at:         172.30.6.149:45605
distributed.worker - INFO -              nanny at:         172.30.6.149:35524
distributed.worker - INFO -              nanny at:         172.30.6.149:39584
distributed.worker - INFO -              nanny at:         172.30.6.149:44106
distributed.worker - INFO -          Listening to:   tcp://172.30.6.149:45718
distributed.worker - INFO -              nanny at:         172.30.6.149:33123
distributed.worker - INFO -              bokeh at:         172.30.6.149:46707
distributed.worker - INFO -          Listening to:   tcp://172.30.6.149:35850
distributed.worker - INFO -              bokeh at:         172.30.6.149:46730
distributed.worker - INFO -          Listening to:   tcp://172.30.6.149:46683
distributed.worker - INFO -              bokeh at:         172.30.6.149:38582
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO -              bokeh at:         172.30.6.149:37005
distributed.worker - INFO -              bokeh at:         172.30.6.149:33777
distributed.worker - INFO -              nanny at:         172.30.6.149:40650
distributed.worker - INFO -              bokeh at:         172.30.6.149:33358
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO -              nanny at:         172.30.6.149:43812
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.149:40630
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -              nanny at:         172.30.6.149:36102
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO -              bokeh at:         172.30.6.149:42977
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -              bokeh at:         172.30.6.149:46276
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:   tcp://172.30.6.149:40630
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO -              bokeh at:         172.30.6.149:41589
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-qkkw85cz', purging
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -              nanny at:         172.30.6.149:45783
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-72kk6y2j
distributed.worker - INFO -              bokeh at:         172.30.6.149:34209
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-mk6pxmny
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-oua_emf3
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-ude7kfox
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-sr02buwx
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-0ku05jfd
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-yw83g3ae
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-iu_v7zh2
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-yal5szc_
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-7wo4w94p
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:34411
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:34411
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:34411
distributed.core - INFO - Starting established connection
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.149:41370
distributed.worker - INFO -          Listening to:   tcp://172.30.6.149:41370
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.149:33393
distributed.worker - INFO -              nanny at:         172.30.6.149:40790
distributed.worker - INFO -          Listening to:   tcp://172.30.6.149:33393
distributed.worker - INFO -              bokeh at:         172.30.6.149:44135
distributed.worker - INFO -              nanny at:         172.30.6.149:32881
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO -              bokeh at:         172.30.6.149:46638
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-u6f_k9ep
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-t36m0x_2
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.149:43047
distributed.worker - INFO -          Listening to:   tcp://172.30.6.149:43047
distributed.worker - INFO -              nanny at:         172.30.6.149:42336
distributed.worker - INFO -              bokeh at:         172.30.6.149:38496
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-r41g87kh
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:34411
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:34411
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:34411
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.149:40238
distributed.worker - INFO -          Listening to:   tcp://172.30.6.149:40238
distributed.worker - INFO -              nanny at:         172.30.6.149:34730
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-zgazwzb8', purging
distributed.worker - INFO -              bokeh at:         172.30.6.149:32910
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-278ui2yc
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:34411
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-v_oxutmz', purging
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.149:42210
distributed.worker - INFO -          Listening to:   tcp://172.30.6.149:42210
distributed.worker - INFO -              nanny at:         172.30.6.149:40730
distributed.worker - INFO -              bokeh at:         172.30.6.149:45119
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-n6ur_tfn
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.149:42985
distributed.worker - INFO -          Listening to:   tcp://172.30.6.149:42985
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.149:44975
distributed.worker - INFO -          Listening to:   tcp://172.30.6.149:44975
distributed.worker - INFO -              nanny at:         172.30.6.149:39438
distributed.worker - INFO -              nanny at:         172.30.6.149:35819
distributed.worker - INFO -              bokeh at:         172.30.6.149:35002
distributed.worker - INFO -              bokeh at:         172.30.6.149:37621
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-ipxb8lge
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-fwa6_qth
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:34411
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.149:36847
distributed.core - INFO - Starting established connection
distributed.worker - INFO -          Listening to:   tcp://172.30.6.149:36847
distributed.worker - INFO -              nanny at:         172.30.6.149:41178
distributed.worker - INFO -              bokeh at:         172.30.6.149:34406
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-bpfr9b7z
distributed.worker - INFO - -------------------------------------------------
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-8d7s3ndc', purging
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:34411
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:34411
distributed.core - INFO - Starting established connection
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:34411
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-qbtnk828', purging
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.149:37798
distributed.worker - INFO -          Listening to:   tcp://172.30.6.149:37798
distributed.worker - INFO -              nanny at:         172.30.6.149:33665
distributed.worker - INFO -              bokeh at:         172.30.6.149:37748
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-koamrl6a
distributed.worker - INFO - -------------------------------------------------
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-_x0ixtar', purging
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:34411
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-0l50llec', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-_pt7lxy6', purging
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.149:42579
distributed.worker - INFO -          Listening to:   tcp://172.30.6.149:42579
distributed.worker - INFO -              nanny at:         172.30.6.149:45937
distributed.worker - INFO -              bokeh at:         172.30.6.149:37791
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-_hl5lk5r
distributed.worker - INFO - -------------------------------------------------
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-3qr1hppj', purging
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:34411
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-on4rhz0d', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-j9dpxboh', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-_xjy5hxf', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-kr_4zj4b', purging
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.149:39200
distributed.worker - INFO -          Listening to:   tcp://172.30.6.149:39200
distributed.worker - INFO -              nanny at:         172.30.6.149:42594
distributed.worker - INFO -              bokeh at:         172.30.6.149:40492
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-t0tdn16_
distributed.worker - INFO - -------------------------------------------------
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-2uxpyhrt', purging
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.149:38459
distributed.worker - INFO -          Listening to:   tcp://172.30.6.149:38459
distributed.worker - INFO -              nanny at:         172.30.6.149:34282
distributed.worker - INFO -              bokeh at:         172.30.6.149:36732
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-wywiz99a
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:34411
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:34411
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.149:42462
distributed.core - INFO - Starting established connection
distributed.worker - INFO -          Listening to:   tcp://172.30.6.149:42462
distributed.worker - INFO -              nanny at:         172.30.6.149:42932
distributed.worker - INFO -              bokeh at:         172.30.6.149:44500
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-8rqglpup
distributed.worker - INFO - -------------------------------------------------
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-hmi7l86x', purging
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:34411
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-qbp27a4e', purging
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.149:35255
distributed.worker - INFO -          Listening to:   tcp://172.30.6.149:35255
distributed.worker - INFO -              nanny at:         172.30.6.149:46307
distributed.worker - INFO -              bokeh at:         172.30.6.149:43757
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-pmey0oe8
distributed.worker - INFO - -------------------------------------------------
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-bo4foa25', purging
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:34411
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-2ykisnya', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-jp7bltq9', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-vq5_xpmw', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-01o98ohf', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-9w6d5dr2', purging
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.149:43297
distributed.worker - INFO -          Listening to:   tcp://172.30.6.149:43297
distributed.worker - INFO -              nanny at:         172.30.6.149:42850
distributed.worker - INFO -              bokeh at:         172.30.6.149:41262
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-opv1y1qk
distributed.worker - INFO - -------------------------------------------------
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-kdwzkptk', purging
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.149:44207
distributed.worker - INFO -          Listening to:   tcp://172.30.6.149:44207
distributed.worker - INFO -              nanny at:         172.30.6.149:34853
distributed.worker - INFO -              bokeh at:         172.30.6.149:45139
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:34411
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-_kpu5dgs
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:34411
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-o2nmf27p', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-pdog7mby', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-hfk43599', purging
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.149:41298
distributed.worker - INFO -          Listening to:   tcp://172.30.6.149:41298
distributed.worker - INFO -              nanny at:         172.30.6.149:33124
distributed.worker - INFO -              bokeh at:         172.30.6.149:38629
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-3olhwyp2
distributed.worker - INFO - -------------------------------------------------
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-aulzdz5m', purging
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:34411
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-crval6zp', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-7pa83pnb', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-zw469ft9', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-92d2hsmg', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-47yduwhl', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-lhy_fgom', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-l9oxxco3', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-amyudmy9', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-0gmzzjy9', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-dfzg41uy', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-9wi2m7ec', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-kmygdjmh', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-y1z5sn4y', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-ejj9djqu', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-ntvy9lkn', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-wvvynyth', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-56zyyeju', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-4i4a5nj0', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-om13h8ka', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-65lv3a16', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-sx_5a6ur', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-6gy_abv7', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-9ayt0ptc', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-_7xan074', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-5rsk5nly', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-61fsbp5_', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-jyjgg2mc', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-c8xh59t2', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-rpiish3v', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-jq9_2ejk', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-h36m34pa', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-ydjcg_ov', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-bthlg8zl', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-f0yn7rnv', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-ibdd1mll', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-_m53f482', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-0_5kmw6s', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-3waea0bg', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-vc5d8eop', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-322p4y_1', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-8_r_ukkg', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-gxpdneiu', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-guso60xu', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-_ojxz9wx', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-69jkcfmb', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-wzcnhotf', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-uhyxrz79', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-vza4cixd', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-xaf0la9a', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-p40xztyy', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-vbj33lb0', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-vh385bsb', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-k51ilbap', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-nvem76pw', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-la82wuv2', purging
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:34411
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:34411
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:34411
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:34411
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:34411
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:34411
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:34411
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-jpjx2rx4', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-zx0_yr8_', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-z_0tfv6c', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-_c8eek43', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-5su99zjd', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-pq4_qjgu', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-nn1t277n', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-kagb40sj', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-dfvj_nd7', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-sg9qi8k1', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-qssdnf6j', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-d5lvx86_', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-nybyvtbz', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-1xmqo34u', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-v_9h_yd4', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-vvd_pirv', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-y17x8wsc', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-sfitc9su', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-nzl1d4jv', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-5vf0u0_m', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-r9dn_5q4', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-5gbsh4yc', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-r2kfnyhm', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-11j4p7vp', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-cp9hcoho', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-v_vaiq1k', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-rj0twf1v', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-us7u5kdf', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-ruojkddi', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-1rq91gl9', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-ym2jd_1c', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-gesqo7m_', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-nj0_hgiv', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-c3vpv03j', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-l1ve23zr', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-3sr51d9n', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-4pgdgxug', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-o7i4kr4u', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-ueat8tc_', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-pqwmjntk', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-gq0121hd', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-1sqotub2', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-w3rc7m5x', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-tf5nxv9y', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-l15xdvjl', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-gwh614g5', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-y6vant2z', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-8wfbdhqk', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-gs8n80b6', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-d5340c5i', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-u6ouw0sr', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-dljj3ata', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-qaiv5ets', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-jjm9ol1e', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-6wamxy59', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-84q1gvtx', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-sbxvophv', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-q_uqdys5', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-xbhnrzud', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-myk00w6e', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-wa5ryddl', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-4kc2z_1c', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-fsuaarln', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-8nbu54nr', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-piaq4gkp', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-fwos48ct', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-lnsc1eoe', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-0z3pj6qt', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-isj9tdog', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-khifz_bf', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-tznv6k38', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-pe3e7hiq', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-usad69qg', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-2rnk_78j', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-9bpb0izb', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-n9mvu0bw', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-a9x45jlv', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-wyd8y0ak', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-zitmzqsb', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-n_nf1won', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-ogbnn26i', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-yhoi7tbi', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-xpgdxhtj', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-3qvuuw_i', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-bjvydifs', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-ykgca9_x', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-m38h1enn', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-rqac4lp4', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-2lr4we7g', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-mvzb5huf', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-qgro2q0x', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-5ticuh4s', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-evhfb62r', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-9yrjlfx9', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-dbcz_c5c', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-nppalkdr', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-iylmbclv', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-jtkl0ibg', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-_xjhgnc3', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-re7zvqik', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-ta7kp6bq', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-emght9f3', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-fb0jb793', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-38ia24ul', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-jcyfsyco', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-603lp8sy', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-w1ub12m4', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-unjkc_7m', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-i40qq2je', purging
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/contextlib.py:119: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.149:41454
distributed.worker - INFO -          Listening to:   tcp://172.30.6.149:41454
distributed.worker - INFO -              nanny at:         172.30.6.149:33486
distributed.worker - INFO -              bokeh at:         172.30.6.149:38100
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-hccigjli
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:34411
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Event loop was unresponsive in Worker for 5.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.utils_perf - INFO - full garbage collection released 10.61 MB from 4308 reference cycles (threshold: 10.00 MB)
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:34411
distributed.worker - INFO - Stopping worker at tcp://172.30.6.149:33393
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.149:32881'
distributed.worker - INFO - Stopping worker at tcp://172.30.6.149:36847
distributed.worker - INFO - Stopping worker at tcp://172.30.6.149:39200
distributed.worker - INFO - Stopping worker at tcp://172.30.6.149:38459
distributed.worker - INFO - Stopping worker at tcp://172.30.6.149:44207
distributed.worker - INFO - Stopping worker at tcp://172.30.6.149:40630
distributed.worker - INFO - Stopping worker at tcp://172.30.6.149:43297
distributed.worker - INFO - Stopping worker at tcp://172.30.6.149:35255
distributed.worker - INFO - Stopping worker at tcp://172.30.6.149:43047
distributed.worker - INFO - Stopping worker at tcp://172.30.6.149:42985
distributed.worker - INFO - Stopping worker at tcp://172.30.6.149:44975
distributed.worker - INFO - Stopping worker at tcp://172.30.6.149:42462
distributed.worker - INFO - Stopping worker at tcp://172.30.6.149:36650
distributed.worker - INFO - Stopping worker at tcp://172.30.6.149:42579
distributed.worker - INFO - Stopping worker at tcp://172.30.6.149:41370
distributed.worker - INFO - Stopping worker at tcp://172.30.6.149:42210
distributed.worker - INFO - Stopping worker at tcp://172.30.6.149:40238
distributed.worker - INFO - Stopping worker at tcp://172.30.6.149:41298
distributed.worker - INFO - Stopping worker at tcp://172.30.6.149:37798
distributed.worker - INFO - Stopping worker at tcp://172.30.6.149:45718
distributed.worker - INFO - Stopping worker at tcp://172.30.6.149:41454
distributed.worker - INFO - Stopping worker at tcp://172.30.6.149:41747
distributed.worker - INFO - Stopping worker at tcp://172.30.6.149:44780
distributed.worker - INFO - Stopping worker at tcp://172.30.6.149:33285
distributed.worker - INFO - Stopping worker at tcp://172.30.6.149:46683
distributed.worker - INFO - Stopping worker at tcp://172.30.6.149:38348
distributed.worker - INFO - Stopping worker at tcp://172.30.6.149:35850
distributed.worker - INFO - Stopping worker at tcp://172.30.6.149:42207
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.149:42594'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.149:44106'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.149:41178'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.149:34282'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.149:45605'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.149:34853'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.149:42336'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.149:45783'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.149:38043'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.149:36102'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.149:40650'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.149:33486'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.149:42850'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.149:33123'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.149:43812'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.149:39438'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.149:35819'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.149:40790'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.149:33124'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.149:45937'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.149:40730'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.149:46307'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.149:35524'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.149:42932'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.149:34730'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.149:33665'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.149:39584'
distributed.dask_worker - INFO - End worker
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
